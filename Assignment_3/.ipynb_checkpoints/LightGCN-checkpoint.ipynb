{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda activate reco_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ADM Assignment 3\\recommenders\n"
     ]
    }
   ],
   "source": [
    "cd D:\\ADM Assignment 3\\recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas version: 1.0.1\n",
      "Tensorflow version: 1.15.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import os\n",
    "import papermill as pm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from reco_utils.common.timer import Timer\n",
    "from reco_utils.recommender.deeprec.models.graphrec.lightgcn import LightGCN\n",
    "from reco_utils.recommender.deeprec.DataModel.ImplicitCF import ImplicitCF\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.python_splitters import python_stratified_split\n",
    "from reco_utils.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "from reco_utils.common.constants import SEED as DEFAULT_SEED\n",
    "from reco_utils.recommender.deeprec.deeprec_utils import prepare_hparams\n",
    "\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Select MovieLens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'\n",
    "\n",
    "# Model parameters\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "SEED = DEFAULT_SEED  # Set None for non-deterministic results\n",
    "\n",
    "yaml_file = \"D:/ADM Assignment 3/recommenders/reco_utils/recommender/deeprec/config/lightgcn.yaml\"\n",
    "user_file = \"../../tests/resources/deeprec/lightgcn/user_embeddings.csv\"\n",
    "item_file = \"../../tests/resources/deeprec/lightgcn/item_embeddings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████████                                                                                                                      | 378/4.81k [00:00<00:10, 406KB/s]"
     ]
    }
   ],
   "source": [
    "df = movielens.load_pandas_df(size=MOVIELENS_DATA_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp\n",
       "0     196     242     3.0  881250949\n",
       "1     186     302     3.0  891717742\n",
       "2      22     377     1.0  878887116\n",
       "3     244      51     2.0  880606923\n",
       "4     166     346     1.0  886397596"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_stratified_split(df, ratio=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImplicitCF(train=train, test=test, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hparams = prepare_hparams(yaml_file,\n",
    "                          n_layers=3,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          epochs=EPOCHS,\n",
    "                          learning_rate=0.005,\n",
    "                          eval_epoch=5,\n",
    "                          top_k=TOP_K,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\graphrec\\lightgcn.py:37: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\graphrec\\lightgcn.py:68: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\DataModel\\ImplicitCF.py:179: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -0.5).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using xavier initialization.\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\graphrec\\lightgcn.py:147: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\graphrec\\lightgcn.py:104: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\graphrec\\lightgcn.py:105: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\graphrec\\lightgcn.py:107: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\graphrec\\lightgcn.py:108: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\graphrec\\lightgcn.py:108: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ADM Assignment 3\\recommenders\\reco_utils\\recommender\\deeprec\\models\\graphrec\\lightgcn.py:109: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LightGCN(hparams, data, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (train)7.4s: train loss = 0.47059 = (mf)0.47034 + (embed)0.00025\n",
      "Epoch 2 (train)5.3s: train loss = 0.27253 = (mf)0.27182 + (embed)0.00070\n",
      "Epoch 3 (train)5.2s: train loss = 0.24397 = (mf)0.24307 + (embed)0.00089\n",
      "Epoch 4 (train)5.2s: train loss = 0.22951 = (mf)0.22845 + (embed)0.00106\n",
      "Epoch 5 (train)5.3s + (eval)0.7s: train loss = 0.22529 = (mf)0.22412 + (embed)0.00117, recall = 0.16052, ndcg = 0.34971, precision = 0.30445, map = 0.09283\n",
      "Epoch 6 (train)5.5s: train loss = 0.21715 = (mf)0.21588 + (embed)0.00127\n",
      "Epoch 7 (train)5.3s: train loss = 0.20724 = (mf)0.20586 + (embed)0.00138\n",
      "Epoch 8 (train)5.2s: train loss = 0.19893 = (mf)0.19742 + (embed)0.00152\n",
      "Epoch 9 (train)5.6s: train loss = 0.18752 = (mf)0.18587 + (embed)0.00165\n",
      "Epoch 10 (train)5.5s + (eval)0.3s: train loss = 0.18446 = (mf)0.18265 + (embed)0.00181, recall = 0.17741, ndcg = 0.38339, precision = 0.33499, map = 0.10538\n",
      "Epoch 11 (train)5.2s: train loss = 0.17381 = (mf)0.17186 + (embed)0.00195\n",
      "Epoch 12 (train)5.3s: train loss = 0.17008 = (mf)0.16799 + (embed)0.00209\n",
      "Epoch 13 (train)5.4s: train loss = 0.16661 = (mf)0.16441 + (embed)0.00221\n",
      "Epoch 14 (train)5.2s: train loss = 0.16238 = (mf)0.16006 + (embed)0.00233\n",
      "Epoch 15 (train)5.2s + (eval)0.3s: train loss = 0.16431 = (mf)0.16189 + (embed)0.00242, recall = 0.19072, ndcg = 0.40077, precision = 0.35302, map = 0.11388\n",
      "Epoch 16 (train)5.3s: train loss = 0.15947 = (mf)0.15696 + (embed)0.00251\n",
      "Epoch 17 (train)5.3s: train loss = 0.15791 = (mf)0.15531 + (embed)0.00260\n",
      "Epoch 18 (train)5.2s: train loss = 0.15659 = (mf)0.15389 + (embed)0.00270\n",
      "Epoch 19 (train)5.2s: train loss = 0.15422 = (mf)0.15143 + (embed)0.00278\n",
      "Epoch 20 (train)5.4s + (eval)0.4s: train loss = 0.14990 = (mf)0.14701 + (embed)0.00288, recall = 0.19770, ndcg = 0.42069, precision = 0.36681, map = 0.12243\n",
      "Epoch 21 (train)5.6s: train loss = 0.14661 = (mf)0.14362 + (embed)0.00298\n",
      "Epoch 22 (train)5.6s: train loss = 0.14605 = (mf)0.14296 + (embed)0.00309\n",
      "Epoch 23 (train)5.8s: train loss = 0.14304 = (mf)0.13984 + (embed)0.00320\n",
      "Epoch 24 (train)5.6s: train loss = 0.14238 = (mf)0.13909 + (embed)0.00330\n",
      "Epoch 25 (train)5.3s + (eval)0.3s: train loss = 0.13935 = (mf)0.13595 + (embed)0.00340, recall = 0.20332, ndcg = 0.43124, precision = 0.37794, map = 0.12811\n",
      "Epoch 26 (train)5.2s: train loss = 0.13817 = (mf)0.13464 + (embed)0.00352\n",
      "Epoch 27 (train)5.2s: train loss = 0.13580 = (mf)0.13218 + (embed)0.00362\n",
      "Epoch 28 (train)5.2s: train loss = 0.13404 = (mf)0.13030 + (embed)0.00374\n",
      "Epoch 29 (train)5.2s: train loss = 0.13255 = (mf)0.12870 + (embed)0.00385\n",
      "Epoch 30 (train)5.8s + (eval)0.4s: train loss = 0.12956 = (mf)0.12559 + (embed)0.00396, recall = 0.20539, ndcg = 0.44011, precision = 0.38452, map = 0.13093\n",
      "Epoch 31 (train)5.7s: train loss = 0.12588 = (mf)0.12179 + (embed)0.00409\n",
      "Epoch 32 (train)5.5s: train loss = 0.12529 = (mf)0.12108 + (embed)0.00421\n",
      "Epoch 33 (train)5.4s: train loss = 0.12471 = (mf)0.12038 + (embed)0.00432\n",
      "Epoch 34 (train)5.3s: train loss = 0.12074 = (mf)0.11630 + (embed)0.00445\n",
      "Epoch 35 (train)5.7s + (eval)0.4s: train loss = 0.11941 = (mf)0.11483 + (embed)0.00458, recall = 0.20940, ndcg = 0.44503, precision = 0.38887, map = 0.13386\n",
      "Epoch 36 (train)5.3s: train loss = 0.11890 = (mf)0.11421 + (embed)0.00469\n",
      "Epoch 37 (train)5.4s: train loss = 0.11990 = (mf)0.11511 + (embed)0.00480\n",
      "Epoch 38 (train)5.3s: train loss = 0.11502 = (mf)0.11009 + (embed)0.00493\n",
      "Epoch 39 (train)5.4s: train loss = 0.11346 = (mf)0.10841 + (embed)0.00505\n",
      "Epoch 40 (train)5.6s + (eval)0.4s: train loss = 0.11311 = (mf)0.10794 + (embed)0.00518, recall = 0.21364, ndcg = 0.45232, precision = 0.39597, map = 0.13582\n",
      "Epoch 41 (train)5.5s: train loss = 0.11038 = (mf)0.10510 + (embed)0.00528\n",
      "Epoch 42 (train)5.5s: train loss = 0.11173 = (mf)0.10631 + (embed)0.00542\n",
      "Epoch 43 (train)5.4s: train loss = 0.10731 = (mf)0.10179 + (embed)0.00552\n",
      "Epoch 44 (train)5.3s: train loss = 0.10573 = (mf)0.10008 + (embed)0.00565\n",
      "Epoch 45 (train)5.3s + (eval)0.3s: train loss = 0.10621 = (mf)0.10044 + (embed)0.00577, recall = 0.21322, ndcg = 0.45376, precision = 0.39936, map = 0.13588\n",
      "Epoch 46 (train)5.4s: train loss = 0.10458 = (mf)0.09869 + (embed)0.00589\n",
      "Epoch 47 (train)5.3s: train loss = 0.10081 = (mf)0.09478 + (embed)0.00603\n",
      "Epoch 48 (train)5.2s: train loss = 0.10134 = (mf)0.09517 + (embed)0.00617\n",
      "Epoch 49 (train)5.3s: train loss = 0.10057 = (mf)0.09430 + (embed)0.00628\n",
      "Epoch 50 (train)5.6s + (eval)0.3s: train loss = 0.10040 = (mf)0.09400 + (embed)0.00640, recall = 0.21342, ndcg = 0.45425, precision = 0.39862, map = 0.13625\n",
      "Took 275.27617879999997 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    model.fit()\n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5.616610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>5.236757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>475</td>\n",
       "      <td>5.169390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "      <td>5.104498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "      <td>5.097010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  prediction\n",
       "0       1       7    5.616610\n",
       "1       1      89    5.236757\n",
       "2       1     475    5.169390\n",
       "3       1     210    5.104498\n",
       "4       1     127    5.097010"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_scores = model.recommend_k_items(test, top_k=TOP_K, remove_seen=True)\n",
    "\n",
    "topk_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP:\t0.136253\n",
      "NDCG:\t0.454250\n",
      "Precision@K:\t0.398621\n",
      "Recall@K:\t0.213418\n"
     ]
    }
   ],
   "source": [
    "eval_map = map_at_k(test, topk_scores, k=TOP_K)\n",
    "eval_ndcg = ndcg_at_k(test, topk_scores, k=TOP_K)\n",
    "eval_precision = precision_at_k(test, topk_scores, k=TOP_K)\n",
    "eval_recall = recall_at_k(test, topk_scores, k=TOP_K)\n",
    "\n",
    "print(\"MAP:\\t%f\" % eval_map,\n",
    "      \"NDCG:\\t%f\" % eval_ndcg,\n",
    "      \"Precision@K:\\t%f\" % eval_precision,\n",
    "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'papermill' has no attribute 'record'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ebeebc47219a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ndcg\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_ndcg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"precision\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_precision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"recall\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_recall\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'papermill' has no attribute 'record'"
     ]
    }
   ],
   "source": [
    "pm.record(\"map\", eval_map)\n",
    "pm.record(\"ndcg\", eval_ndcg)\n",
    "pm.record(\"precision\", eval_precision)\n",
    "pm.record(\"recall\", eval_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.infer_embedding(user_file, item_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\verle\\Assignment_3_Recommendation\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\verle\\Assignment_3_Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LightGCN.sav']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'LightGCN.sav'\n",
    "joblib.dump(topk_scores, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topk_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d3ff322d0e97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtopk_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LightGCN.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'topk_scores' is not defined"
     ]
    }
   ],
   "source": [
    "topk_scores.to_csv(\"LightGCN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
